id: fd-009
name: Team Collaboration & Communication
slug: team-collaboration-communication
status: ready
strategic_context:
  problem_statement: 'Knowledge work requires continuous collaboration and context sharing, but traditional communication tools (email, Slack) fragment conversations away from the actual work artifacts. Research shows knowledge workers spend 28% of their workweek reading and responding to communications, with 60% of that time wasted searching for context scattered across multiple tools. When discussions happen in separate channels from documents/projects, teams lose critical decision context - 45% of project decisions lack documented rationale making it difficult to understand why choices were made months later. This context fragmentation creates knowledge silos, duplicated conversations (same question asked in 3 different Slack channels), and onboarding challenges (new team members cannot reconstruct decision history). The lack of structured collaboration within work artifacts leads to miscommunication (assumptions not validated), delayed decisions (waiting for synchronous meetings), and institutional knowledge loss when team members leave.

  '
  market_context: 'Context-aware collaboration is emerging as a key differentiator in knowledge work platforms, with Notion comments, Figma multiplayer, and Linear discussions setting market expectations. Organizations expect collaboration features embedded directly in work artifacts rather than separate communication tools. The trend toward async-first work culture (driven by distributed teams across time zones) requires threaded discussions with clear resolution states - 65% of knowledge workers prefer async written communication over synchronous meetings for non-urgent topics. Key competitive requirements include: inline commenting on specific content sections, @mentions for targeted notifications, discussion threading with reply context, resolution workflows (mark discussion as resolved), and activity feeds showing recent team activity. Products that force users to switch between work artifacts and separate communication tools create context-switching overhead (average 23 minutes lost per switch) and information fragmentation. The integration of AI assistants into collaboration workflows (summarizing discussions, suggesting related context) is becoming table-stakes for premium tiers.

  '
  contributes_to:
  - Product.Deliver.Execution
  - OrgOps.Coordinate.Workflows
  - Product.Operate.Quality
  tracks:
  - product
  - org_ops
  success_metrics:
  - metric: Context-switching frequency
    target: Reduce external tool switches from 45 per day to <15 per day by embedding collaboration in work artifacts
    measurement: User activity logs tracking navigation between platform and external communication tools (Slack, email) per active user per day
  - metric: Decision documentation completeness
    target: Increase documented decision rationale from 45% to 80% of major project decisions through inline discussion capture
    measurement: Content analysis of project artifacts comparing decisions with linked discussion threads before/after deployment
  - metric: Question resolution time
    target: Decrease average time from question asked to answer provided from 6 hours to <2 hours through targeted @mentions and notifications
    measurement: Discussion thread analytics tracking time between initial comment creation and first response with resolution marking
definition:
  job_to_be_done: When team members need to discuss work artifacts, ask questions, or make decisions, they want contextual collaboration tools embedded directly in the work, so they can maintain context, document decisions, and reduce communication fragmentation across multiple tools.
  solution_approach: The platform provides inline commenting on any content element (documents, knowledge graph nodes, project tasks, feature definitions) with threaded discussions, @mention notifications, and resolution workflows. Users can start discussions directly on specific content sections maintaining spatial context (comment anchored to paragraph/section/node). Discussions support rich formatting, file attachments, and @mentions triggering targeted notifications. Each discussion thread has lifecycle states (open, resolved, archived) with clear ownership and resolution criteria. Activity feeds provide team-level and personal views showing recent comments, mentions, and discussions requiring attention. The system maintains full discussion history as institutional memory, searchable and linkable from future work. AI assists by summarizing long discussion threads, suggesting related past discussions, and highlighting unresolved questions.
  capabilities:
  - id: cap-001
    name: Inline Contextual Comments
    description: 'Add comments directly on any content element maintaining spatial context and anchor to specific sections. Users can comment on document paragraphs, knowledge graph entities, project tasks, feature capabilities, or any discrete content unit. Comments are visually anchored to content with hover indicators and sidebar display showing comment threads for selected content. Supports comment creation modes: inline (click content element and add comment), selection-based (highlight text and comment on selection), and global (comment on overall artifact without specific anchor). Comments include rich text formatting (bold, italic, code blocks, lists), file attachments (images, PDFs, videos), and external link embedding. System maintains comment position stability even when surrounding content changes through smart anchor tracking. Provides comment density visualization showing which content sections have active discussions.

      '
  - id: cap-002
    name: Threaded Discussion Management
    description: 'Organize comments into threaded discussions with reply chains, topic grouping, and conversation flow. Each comment can have nested replies creating discussion trees up to 5 levels deep. Users can follow discussion threads to receive notifications for new replies even if not directly mentioned. Threads support reordering (sort by chronological, most recent, most reactions) and filtering (show only unresolved, show only my threads, show mentions only). Discussion threads have metadata: creator, creation time, last activity time, participant count, resolution status. Users can quote specific replies when responding to maintain context in long threads. System detects and suggests merging duplicate discussions on same topic. Provides discussion summary view showing key points from long threads (AI-generated or user-curated). Supports marking key comments as "decision point" or "action item" for easy reference.

      '
  - id: cap-003
    name: Smart @Mention Notifications
    description: 'Target specific team members using @mentions triggering contextual notifications with discussion excerpt and direct link. Users can @mention individuals (@john), roles (@project-owner), or teams (@compliance-team) expanding to all members. Mentions generate notifications through multiple channels based on user preferences: in-app notification center, email digest (immediate, hourly, daily), Slack/Teams integration if connected. Notifications include discussion context: quoted comment text (first 200 chars), artifact name and type, discussion thread summary, direct link to specific comment. System intelligently batches related notifications (5 comments on same artifact â†’ 1 notification with all context). Supports notification preferences per context type (immediate for @mentions, daily digest for general activity). Provides "smart mentions" suggesting relevant people based on content expertise, previous discussion participation, or project role. Users can mute specific discussion threads to stop receiving notifications without leaving conversation.

      '
  - id: cap-004
    name: Discussion Resolution Workflows
    description: 'Mark discussions as resolved, track resolution status, and maintain audit trail of decision outcomes. Discussion creators or project owners can mark threads as resolved when questions are answered or decisions are made. Resolved discussions show resolution metadata: resolved by (user), resolved at (timestamp), resolution summary (optional text explaining outcome). System prompts for resolution summary encouraging decision documentation (e.g., "Question: Should we use API v2? Resolution: Yes, using v2 for better auth support"). Resolved threads collapse by default but remain accessible with "show resolved" toggle. Users can reopen resolved discussions if new information emerges or decision needs revisiting. Analytics track discussion resolution time by topic, team, and priority. Provides "stale discussion detection" flagging threads with >5 replies but no activity in 7+ days suggesting resolution or archival. Supports approval workflows where discussions require explicit approval from designated reviewers before marking as resolved.

      '
  - id: cap-005
    name: Activity Feed & Notification Center
    description: 'Aggregate team activity and personal notifications in unified feeds showing recent collaboration across all work artifacts. Personal notification center shows items requiring user attention: @mentions, replies to user comments, discussions user is following, unresolved questions on user-owned artifacts. Team activity feed shows recent collaboration across team workspace: new comments, resolved discussions, major decisions documented, active threads by topic. Feeds support filtering (by artifact type, by user, by time range, by resolved status) and search (find discussions mentioning specific terms). Each feed item shows context preview: artifact name, discussion excerpt, participant avatars, activity timestamp, resolution status. Users can act directly from feed: reply to comment, mark resolved, mute thread, open full artifact context. System provides activity digests (daily/weekly email summaries) for users who prefer batch review over continuous notifications. Includes "caught up" indicator showing when user has reviewed all new activity since last visit.

      '
  contexts:
  - id: ctx-001
    type: ui
    name: Document with Inline Comment Thread
    description: 'Document editing view showing content with inline comment threads anchored to specific paragraphs or sections. Users access this context when reviewing documents, participating in discussions, or adding feedback on specific content. Comments appear in right sidebar aligned with anchored content sections, with visual indicators (comment count bubbles) on content elements. Essential for contextual collaboration without leaving document context or switching to separate communication tools.'
    key_interactions:
    - Click content element (paragraph, heading, list item) to add new comment
    - Highlight text selection and click comment button to anchor comment to specific phrase
    - View comment threads in right sidebar with expand/collapse controls
    - Reply to existing comments creating nested discussion threads
    - Use @mention autocomplete to tag specific team members
    data_displayed:
    - Document content with visual comment indicators (bubbles showing comment count per section)
    - Comment sidebar showing all threads for current content with creator avatars and timestamps
    - Individual comments with rich text formatting, attachments, and @mention highlights
    - Resolution status badges (Open, Resolved, Archived) per discussion thread
    - Active participants list showing who is currently viewing or commenting
    - Unresolved comment count summary at document top
  - id: ctx-002
    type: ui
    name: Personal Notification Center
    description: 'Dedicated notification interface showing all activity requiring user attention organized by priority and type. Users access this from persistent notification icon in app header showing unread count badge. The center provides quick overview of mentions, replies, and discussion activity without requiring navigation to each artifact. Critical for staying informed across multiple projects and artifacts without constant context switching.

      '
    key_interactions:
    - View notifications grouped by type (@mentions, replies, followed discussions, approvals needed)
    - Filter notifications by artifact type, time range, or resolution status
    - Click notification to open artifact at exact comment location
    - Mark notifications as read individually or in bulk
    - Mute discussion threads directly from notification center
    data_displayed:
    - Notification list with context previews (artifact name, comment excerpt, discussion participants)
    - Unread count badge showing total notifications requiring attention
    - Notification timestamp with relative time (2 hours ago, yesterday, last week)
    - Thread preview showing recent activity in discussion (last 3 comments visible)
    - Quick actions per notification (mark read, mute thread, open artifact)
    - "Filter controls showing notification counts by category (@mentions: 5, replies: 12, etc.)"
  - id: ctx-003
    type: ui
    name: Team Activity Feed Dashboard
    description: 'Team-level activity stream showing recent collaboration across all team projects and artifacts. Team managers and members access this to stay aware of team discussions, identify active topics, and discover relevant conversations they might want to join. Provides ambient awareness of team collaboration patterns without requiring presence in every discussion. Important for team cohesion and knowledge sharing in async-first environments.

      '
    key_interactions:
    - Scroll chronological activity feed showing recent comments, resolutions, and discussions
    - Filter activity by team member, artifact type, or topic tags
    - Click activity item to open full discussion context in source artifact
    - Follow interesting discussions to receive notifications for future activity
    - Search activity feed for past discussions on specific topics or keywords
    data_displayed:
    - Activity items showing action type (new comment, discussion resolved, decision documented)
    - Actor information with avatar, name, and timestamp for each activity
    - Context preview with artifact name, discussion excerpt (first 100 chars), and participant count
    - Thread engagement metrics (reply count, participant count, resolution status)
    - Trending topics widget showing most active discussion themes across team
    - Activity volume chart showing team collaboration patterns over time (hourly, daily, weekly)
  scenarios:
  - id: scn-001
    name: Team Member Asks Question via Inline Comment
    actor: Team Member (Content Contributor) has clarification question about specific document section while reviewing project documentation
    context: The Team Member is reviewing a technical architecture document for an upcoming project implementation. They encounter a section describing database schema design that mentions using "event sourcing pattern" but lacks detail about implementation approach. Without inline commenting, they would need to send Slack message (losing spatial context of which specific paragraph prompted question) or schedule meeting (creating unnecessary synchronous overhead). They want to ask question directly on the confusing content section so context is preserved and answer is documented for future readers encountering same confusion.
    trigger: Team Member selects confusing paragraph text and clicks "Add Comment" button appearing on selection
    action: |-
      Team Member asks question through inline comment workflow in these steps:
      1) Select text "event sourcing pattern for audit trail" in document paragraph. System highlights selection and displays comment button overlay.
      2) Click comment button. System opens comment composer anchored to selected text with text selection quoted in comment context.
      3) Type question in rich text editor: "@sarah - Can you clarify which event sourcing library we're using? Are we implementing custom event store or using existing solution like EventStore or Kafka?" Include @mention to tag document author for notification.
      4) Add formatting using toolbar: bold library names, add bullet points for clarity. System provides real-time preview of formatted comment.
      5) Submit comment. System creates comment thread anchored to selected paragraph, adds visual indicator (comment bubble with count "1") on paragraph, displays comment in sidebar aligned with paragraph location.
      6) System generates notification for @sarah including quoted selection, question text, and direct link to exact document location. Sarah receives notification via her preferred channel (in-app + email).
    outcome: "Question documented as inline comment anchored to specific confusing paragraph maintaining spatial context. Document author (Sarah) receives targeted notification with full context - she doesn't need to ask 'which section are you referring to?' because comment is anchored. Comment visible to all team members who review document - if others have same question they see it's already asked and can follow thread for answer rather than asking duplicate question in separate channel. When Sarah answers, response becomes permanent documentation attached to that specific content section helping future readers. Team Member can continue reviewing document without waiting for answer - they'll receive notification when Sarah responds. The discussion thread creates institutional memory - 6 months later when new team member reviews same document and encounters same confusing section, they see the historical question/answer thread providing immediate clarification without requiring new question. Project manager browsing team activity feed sees this discussion as active item and may decide to update document with clarifying details based on the question/answer exchange."
    acceptance_criteria:
    - Comment created with text selection quoted in thread context showing which specific paragraph prompted question
    - Comment anchored to paragraph with visual indicator (bubble with count 1) visible on hover
    - Notification sent to @sarah within 30 seconds including document name, selected text, and question with direct link
    - Comment appears in document sidebar aligned with anchored paragraph position
    - Other team members viewing document see comment indicator and can read/follow discussion
    - Team activity feed shows new comment activity with context preview within 1 minute
  - id: scn-002
    name: Discussion Thread Reaches Resolution and Is Documented
    actor: Document Author (Content Owner) responds to question and marks discussion as resolved after reaching decision
    context: Sarah received notification about question on her architecture document regarding event sourcing library choice. She has context from the inline comment (knows exactly which section prompted question, can see full discussion history) and wants to provide detailed answer documenting the decision rationale. After answering, she wants to mark discussion as resolved so it doesn't appear in "unresolved discussions" lists and team knows this topic is settled. The resolution will create permanent decision documentation attached to the content section where decision was made.
    trigger: Sarah clicks notification link in email taking her directly to document at comment location, reads question, and clicks "Reply" button on comment thread
    action: |-
      Document author resolves discussion through these steps:
      1) Click reply button on Team Member's question comment. System opens reply composer nested under original question in thread.
      2) Type comprehensive answer: "We're using EventStoreDB (previously known as Event Store) for our event sourcing implementation. We evaluated custom vs existing solution and chose EventStoreDB because: (1) Mature community and documentation, (2) Built-in projections support, (3) Already used successfully by our partner team. I'll add implementation details to the section." Format answer with numbered list for clarity.
      3) Add reference link to EventStoreDB documentation as attachment in reply. System embeds link preview with title and favicon.
      4) Submit reply. System adds nested reply to thread, increments comment count on paragraph indicator to "2", notifies original question asker (Team Member) of new reply.
      5) Click "Mark Resolved" button on discussion thread. System prompts for resolution summary.
      6) Enter resolution summary: "Decision: Using EventStoreDB for event sourcing. See reply for detailed rationale. Will update document section with implementation details." System saves resolution metadata (resolved by Sarah, resolved at timestamp, resolution summary).
      7) System marks thread as resolved, collapses thread by default but keeps accessible with "Show Resolved" toggle, updates document to show "1 resolved discussion" instead of "1 unresolved discussion", removes thread from Sarah's unresolved items list.
      8) Optionally, Sarah edits document paragraph to incorporate clarification based on question/answer ("We use EventStoreDB for event sourcing pattern providing audit trail - see resolved discussion for library selection rationale"). System maintains comment anchor even as content is edited.
    outcome: "Question answered with detailed rationale documented in discussion thread attached to specific content section. Resolution summary captures decision outcome in structured format making it easy to understand conclusion without reading full thread. Original question asker (Team Member) receives notification of answer and can see discussion is resolved - they know question is settled and don't need to follow up. Other team members viewing document see resolved discussion indicator - they can expand to read full Q&A if interested but resolved status signals this topic doesn't need their attention. The discussion thread with resolution summary becomes permanent institutional knowledge - when project is handed off to operations team 6 months later, they can read through resolved discussions to understand design decisions and rationale. Team Lead reviewing team activity feed sees discussion resolution as recent activity showing active collaboration and decision documentation on the team. Analytics track that this discussion was resolved in 2 hours (from question to resolution) demonstrating efficient async communication compared to 6-hour average before inline collaboration tools. The resolution summary is searchable - future team members searching for 'event sourcing' or 'EventStoreDB' will find this discussion thread with decision context."
    acceptance_criteria:
    - Reply added to thread with nested indentation showing it's response to original question
    - Notification sent to original question asker within 30 seconds with reply preview and link
    - Discussion thread marked as resolved with resolution summary and metadata (resolver, timestamp) visible
    - Resolved thread collapses by default but remains accessible via Show Resolved toggle
    - Document summary updates showing 1 resolved discussion instead of 1 unresolved
    - Resolution appears in team activity feed showing Sarah resolved discussion with summary preview
  - id: scn-003
    name: Team Member Discovers Relevant Past Discussion via Search
    actor: New Team Member (Onboarding) searches for context on technical decision while reviewing project materials
    context: A new developer joined the team 2 weeks ago and is reviewing project documentation to understand architecture decisions. They encounter mention of EventStoreDB in code but don't understand why this specific library was chosen over alternatives. In traditional setups, they would need to interrupt senior developers with questions or search through Slack history across multiple channels (often hitting retention limits). With inline discussions preserved, they can search discussion history to find past conversations explaining decisions. This enables self-service onboarding without disrupting team members.
    trigger: New developer types "EventStoreDB" in global search box and filters results to "Discussions" category
    action: |-
      New team member discovers historical decision context through search in these steps:
      1) Enter search query "EventStoreDB why chosen" in global search box at app header. System searches across all content and discussions.
      2) Filter results by "Discussions" category to focus on conversations rather than general content. System shows 3 discussion threads mentioning EventStoreDB.
      3) Review search results preview showing: (a) Resolved discussion on architecture doc: "Decision: Using EventStoreDB for event sourcing. See reply for detailed rationale." (b) Two other discussions mentioning EventStoreDB in different contexts (implementation questions, deployment config).
      4) Click first result (resolved discussion on architecture doc). System navigates to architecture document at exact comment anchor location, highlights comment thread, and expands resolved discussion.
      5) Read original question from Team Member ("Can you clarify which event sourcing library we're using?") and Sarah's detailed answer explaining library choice rationale (mature community, built-in projections, partner team precedent).
      6) Read resolution summary confirming decision outcome. Understand why EventStoreDB was chosen without needing to ask anyone.
      7) Optional: Add follow-up comment asking clarification on specific implementation detail mentioned in resolved discussion ("Thanks for this context! Can you point me to the partner team's implementation for reference?"). System reopens discussion thread or creates new related thread maintaining connection to original decision discussion.
    outcome: "New team member successfully discovers decision context through search without interrupting senior developers. The historical discussion thread provides complete rationale including alternatives considered, evaluation criteria, and decision outcome. This self-service knowledge discovery reduces onboarding time and enables independent learning. The preserved discussion with resolution summary serves as institutional knowledge accessible to all current and future team members. By finding answer themselves, new developer saves 30-60 minutes of senior developer time (avoiding interruption and back-and-forth explanation). They gain confidence in self-sufficiency using platform's knowledge discovery capabilities. The ability to add follow-up comments allows extending historical discussions with new related questions maintaining conversation continuity. Senior developers appreciate reduced interruption frequency for questions with documented answers. Organization benefits from compound knowledge investment - one Q&A exchange 6 months ago continues providing value to multiple new team members during onboarding. Team Lead reviewing onboarding analytics sees that new developers successfully find answers to 70% of initial questions through search/discussions reducing onboarding mentorship overhead from 15 hours to 8 hours per new hire."
    acceptance_criteria:
    - Search query returns relevant discussion threads with preview showing resolution summary
    - Search results filterable by Discussions category isolating conversations from general content
    - Clicking search result navigates to exact document location with comment thread highlighted
    - Resolved discussion expands showing full question, answer, and resolution summary
    - New team member can read complete decision rationale without requiring live explanation
    - Option to add follow-up comment reopening or extending historical discussion thread
  personas:
  - id: content-contributor
    name: Content Contributor
    role: Individual Contributor
    description: Knowledge worker creating and reviewing content (documents, project plans, feature specs) as part of team collaboration. Contributes to 5-10 shared documents per week and reviews/comments on 10-15 documents created by others. Needs efficient async communication tools embedded in content to reduce context switching and maintain focus.
    goals:
    - Ask clarification questions on specific content sections without losing spatial context or switching to separate tools
    - Provide feedback on colleague work through targeted comments rather than lengthy email summaries
    - Stay informed of responses to own questions and comments without constant checking across multiple artifacts
    - Document decisions and discussions inline with content so rationale is preserved for future reference
    pain_points:
    - Switching between work artifacts and Slack for questions loses context - recipients ask "which part?" wasting roundtrips
    - Email feedback on documents lacks specificity - comments like "section 3 needs work" require recipients to guess exact issues
    - Tracking responses across multiple discussions in different tools requires manual checking and mental overhead
    - Important decision context lives in ephemeral Slack threads that disappear after 90-day retention limit
    usage_context: Daily usage when collaborating on documents and projects. Primary interactions are adding comments, replying to discussions, and reviewing activity feed. Weekly usage of search to find past discussion context.
    technical_proficiency: intermediate
    current_situation: "As a product manager collaborating with engineering and design teams on feature specifications, I create 3-5 new documents per week and review/comment on 10-15 documents from colleagues. My current workflow is fragmented across tools - I write specs in Notion, discuss them in Slack, track feedback in Linear comments, and compile everything in Google Docs for stakeholder review. When I have a question about an engineering design doc, I copy the relevant paragraph, paste it into Slack with my question, and @mention the author. This works but loses spatial context - the author has to navigate back to the doc, find the section I'm asking about, and provide answer in Slack. Then I need to manually transfer the answer back to the doc as a comment or just remember the context. When I give design feedback, I write long Slack messages trying to describe which specific screen elements need changes ('the button in the top right, not the bottom one') because I can't point directly at the element. Designers spend 10 minutes decoding my feedback and often implement the wrong changes requiring rework. I follow 8-10 active projects simultaneously and need to check Slack, Linear, Notion, and email to stay informed about discussions relevant to my work. This takes 45-60 minutes per day of context switching and manual checking. I miss important feedback sometimes because it's buried in a Slack thread I forgot to follow. Last month I discovered a critical technical constraint 3 weeks after it was discussed in a Slack channel I wasn't monitoring - if I'd known earlier, I would have adjusted the feature scope differently. When new team members join, they ask questions that were already answered in past Slack discussions, but we hit our 90-day message retention limit so the context is gone. I end up re-explaining the same design decisions multiple times because we have no permanent documentation of discussion rationale."
    transformation_moment: "When our team adopted inline collaboration with contextual comments, my workflow immediately felt more focused and efficient. The first major improvement came when reviewing an engineering design doc - instead of copying paragraphs to Slack, I simply highlighted the confusing sentence, clicked the comment button, and typed my question with @mention right there in the doc. The engineer received a notification with full context (document name, exact sentence highlighted, my question) and replied directly in the comment thread 30 minutes later. No 'which section?' roundtrips, no lost context. I could continue my work and received a notification when the answer arrived. Within the first week, I added comments to 12 different documents (specs, designs, project plans) and every discussion stayed anchored to the specific content section it referenced. The impact on design feedback was dramatic - when reviewing UI mockups, I clicked directly on problematic elements and left comments: 'This button should be secondary style, not primary' with the button highlighted. Designers implemented changes in one pass instead of multiple clarification rounds. My context-switching time dropped from 45 minutes per day to about 15 minutes because the notification center aggregated all discussions requiring my attention - I no longer manually checked Slack, Linear, and Notion separately. The personal activity feed showed me all recent comments on my documents and replies to my questions in chronological order. When I returned from a 3-day weekend, I spent 10 minutes reviewing the feed and was fully caught up on all project discussions. The decision documentation value became clear when a stakeholder questioned our API design approach 2 months after the decision. Instead of trying to remember or reconstruct the rationale, I searched for 'API design' in discussions, found the thread where we debated REST vs GraphQL with detailed pros/cons analysis, and shared the resolved discussion link with stakeholder. They read the complete context including alternatives considered and evaluation criteria, immediately understood the decision, and dropped their objection. New team members onboarding now discover 70% of answers through search/discussions rather than asking live questions - they search for topics, find resolved discussion threads with decision rationale, and learn independently. This reduced my onboarding mentorship time from 12 hours per new PM to about 5 hours focused on topics without documented discussions."
    emotional_resolution: "I now feel focused and in control of my collaboration workflow rather than constantly scattered across multiple tools losing context. The inline comments give me confidence that my questions and feedback are precisely targeted - no more ambiguous 'section 3 needs work' comments that create confusion. I trust that when I ask a question or provide feedback, the recipient has full spatial context without requiring clarification roundtrips. The notification center reduces my anxiety about missing important discussions - I know all activity requiring my attention is aggregated in one place rather than scattered across Slack channels, Linear issues, and Notion pages. I've reclaimed 30 minutes per day previously spent context-switching and manual checking across tools, reinvesting that time into strategic thinking and deep work. When stakeholders challenge decisions, I feel confident sharing discussion threads with complete rationale rather than trying to remember context from memory - the documented decision history serves as objective record. I appreciate that new team members can onboard faster through self-service knowledge discovery reducing my mentorship burden while still providing them with high-quality context from historical discussions. Most importantly, I feel like our institutional knowledge is actually being preserved and compounded - discussions from 6 months ago continue providing value rather than disappearing into Slack retention limits or personal memory silos. This shift from ephemeral to permanent collaboration context has made our team more effective and my individual work more satisfying."
  - id: document-author
    name: Document Author
    role: Content Owner
    description: Subject matter expert responsible for creating and maintaining authoritative documentation (technical specs, process guides, architecture decisions). Creates 5-10 significant documents per quarter that become reference materials for teams. Needs to facilitate discussions on content, answer questions efficiently, and incorporate feedback while maintaining document quality.
    goals:
    - Receive targeted questions on specific content sections with full spatial context to provide precise answers
    - Facilitate productive async discussions on document content without scheduling synchronous review meetings
    - Mark discussions as resolved when questions are answered so document status is clear to other readers
    - Use discussion feedback to improve document content and identify areas needing clarification
    pain_points:
    - Questions via Slack lack context - recipients send screenshots or copy-paste sections trying to indicate what they're asking about
    - Review meetings consume 3-5 hours per week for document feedback that could be handled async with better tools
    - No visibility into which document sections are confusing or need clarification based on reader questions
    - Duplicate questions from multiple readers because previous answers not visible in document context
    usage_context: Weekly usage when publishing new documents and responding to questions. Daily usage during active document review periods. Monthly usage reviewing resolved discussions to identify document improvement opportunities.
    technical_proficiency: advanced
    current_situation: "As the technical architect responsible for system design documentation, I create 8-10 major architecture decision records (ADRs) and technical specs per quarter that serve as reference materials for 30+ engineers across 4 teams. When I publish a new document, I announce it in Slack and invite feedback. Over the next 2-3 weeks, I receive questions through multiple channels - some engineers DM me directly, others post in team Slack channels, a few send emails, and occasionally someone schedules a meeting. Every question requires manual context gathering - if someone asks 'what did you mean by event sourcing pattern?' I have to figure out which document they're referencing (I have 5 active documents) and which specific section mentions event sourcing. Often I ask clarifying questions ('which document are you reading? which section?') adding 2-4 hour delays to simple answers. I schedule document review meetings where team leads and I go through specs page by page discussing feedback. These meetings take 90-120 minutes and often cover content that only 2-3 attendees care about while others multitask. The meetings are necessary because async Slack feedback is too fragmented and lacks structure. When I answer questions in Slack, those answers benefit only the people in that specific channel. Three weeks later, someone from a different team asks the same question and I re-explain the same concept. Last month I answered the same API versioning question 4 separate times to 4 different engineers because my previous answers were scattered across DMs and channels. I have no visibility into which parts of my documents are confusing - I don't know if 10 people struggled with the same section but only 1 asked a question. When updating documents, I rely on memory of which feedback to incorporate rather than having structured collection of discussion feedback tied to specific sections. Six months after publishing an ADR, someone questions the design decision. I struggle to remember the rationale and alternatives we considered. I search through Slack but hit retention limits - the original discussion is gone. I end up saying 'I don't remember exactly why we chose this, but I think it was because...' which undermines confidence in the decision."
    transformation_moment: "When I started using inline collaboration for architecture documentation, the workflow transformation was immediate and dramatic. I published a new ADR describing our migration from REST to GraphQL and received 12 questions over 2 weeks - but this time every question was an inline comment anchored to the exact paragraph or sentence prompting confusion. When engineer asks 'Why GraphQL over REST?' the question appears as a comment thread on the paragraph comparing the two approaches. I click the notification, read the question with full context visible (the paragraph being questioned is right there), and reply directly in the thread with detailed rationale. The answer becomes permanent documentation attached to that specific content section - future readers see the Q&A exchange and don't ask the same question. Within 3 weeks of publishing that ADR, 8 engineers had asked questions via inline comments and all 8 received answers that are now visible to everyone reading the document. The duplicate question rate dropped to zero - when someone has a question, they first check if there's already a comment thread on that section answering it. The spatial context of comments revealed patterns I couldn't see before - I noticed 5 separate questions on the same paragraph about schema versioning, signaling that section needed rewriting. I expanded that paragraph with more detail and marked all 5 discussions as resolved with summary 'Clarified in updated paragraph'. The discussion resolution workflow eliminated review meetings for 70% of my documents - instead of scheduling 90-minute meetings, I publish docs, receive async inline comments over 1-2 weeks, answer questions in threads, incorporate feedback, and mark discussions resolved. Only 30% of documents with complex trade-off discussions now require synchronous review, saving 6-8 hours per month. When stakeholder questioned our GraphQL decision 4 months later, I shared the document link and pointed to resolved discussion threads showing the original debate, alternatives considered, evaluation criteria, and decision rationale. The stakeholder read the complete context, understood our reasoning, and dropped the objection without requiring meeting. The permanent discussion history has become institutional memory - when new architect joined team, they read through our ADRs including all resolved discussion threads, learning not just what decisions were made but why and what alternatives we considered."
    emotional_resolution: "I now feel confident that my documentation serves as effective knowledge transfer rather than just static reference material that generates endless clarification questions. The inline comments give me precise understanding of which content sections need improvement - when I see 3-4 questions clustered on the same paragraph, I know that section is unclear and needs rewriting. I appreciate that every question I answer provides compound value - the answer helps not just the asker but all future readers of that section, dramatically reducing duplicate questions. The discussion resolution workflow gives me satisfying closure - I can mark questions as answered and see 'All discussions resolved' status indicating the document is ready for broad consumption. I've eliminated 6-8 hours per month of review meetings while actually increasing feedback quality because async inline comments give people time to formulate thoughtful questions rather than thinking on the spot in meetings. When decisions are questioned months later, I feel prepared and credible sharing discussion thread links with complete rationale rather than relying on fuzzy memory - the documented decision history protects both the decision quality and my professional credibility. I've noticed my documentation quality improving over time because the pattern of recurring questions guides me to proactively clarify confusing topics in future documents. Most importantly, I feel like my knowledge and expertise are being captured and scaled through discussion documentation rather than being locked in my head or lost to Slack retention limits. This shift from reactive Q&A to permanent knowledge building makes my role more impactful and satisfying."
  - id: project-manager-collab
    name: Project Manager
    role: Project Coordinator
    description: Cross-functional coordinator managing projects involving 8-12 team members across engineering, design, and product. Needs to stay informed of project-related discussions, ensure decisions are documented, and maintain team alignment without attending every conversation. Manages 3-5 concurrent projects requiring visibility into 20-30 active discussions per week.
    goals:
    - Maintain awareness of project-related discussions across multiple work artifacts without requiring participation in every thread
    - Ensure important decisions are documented with rationale rather than existing only in ephemeral communication channels
    - Identify blocked discussions requiring escalation or decision from project leadership
    - Surface relevant past discussions during project planning to leverage institutional knowledge
    pain_points:
    - Missing critical project discussions happening in various Slack channels and document comment threads across tools
    - Important decisions made in ad-hoc conversations lack documentation causing confusion when revisited weeks later
    - No visibility into stale discussions that are blocking progress because no one responded or made decision
    - Onboarding new project members requires manually explaining past decisions because discussion history is fragmented
    usage_context: Daily usage monitoring team activity feed and notification center. Weekly usage reviewing project discussion patterns and resolution rates. Monthly retrospectives using discussion analytics to identify communication bottlenecks.
    technical_proficiency: intermediate
    current_situation: "As a project manager coordinating a 12-person product launch across engineering, design, and product teams, I'm responsible for ensuring team alignment and removing blockers but I'm overwhelmed by fragmented communication. Discussions about the project happen in 6 different Slack channels (engineering-general, design-team, product-launch-2024, random-chatter, plus various DM groups), Linear issue comments, Figma comment threads, and Google Doc suggestions. I cannot possibly monitor all these venues simultaneously. I typically discover important discussions 2-3 days after they happen when someone mentions 'as we discussed in Slack' in a meeting and I have no idea what discussion they're referencing. Last month the engineering team made a significant technical decision (switching database schemas) discussed entirely in their team Slack channel. I wasn't in that channel because it's primarily for technical topics not project management. When the decision impacted project timeline by 2 weeks, I learned about it 5 days later during our status meeting. If I'd known when the discussion started, I could have provided project context that might have influenced the decision or at least proactively communicated timeline impact to stakeholders. I have no systematic way to track unresolved decisions - I know from meetings that we're waiting on several decisions (API design approach, deployment strategy, brand color palette) but I don't have visibility into discussion status for each. I manually follow up in stand-ups asking 'did we decide on X?' often discovering discussion stalled because key person didn't see the question. When new designer joined project mid-flight, I spent 3 hours in onboarding meeting explaining why we chose certain approaches and what alternatives we considered. Most of that context originally existed in Slack discussions but was either beyond retention limit or scattered across too many channels to find. After retrospectives, I create action items like 'document decision rationale better' but we lack tools to systematically capture decision context as discussions happen, so the problem persists."
    transformation_moment: "When my project team adopted inline collaboration with unified activity feeds, my coordination overhead dropped dramatically while visibility improved significantly. The team activity feed became my mission control - every morning I spend 10 minutes scrolling through yesterday's collaboration activity across all project artifacts. I see new comment threads started on technical specs, resolved discussions on design mockups, unresolved questions on project plans, and decision documentation on ADRs, all in one chronological stream. The feed previews give me enough context to understand what's being discussed ('Question on API auth strategy in backend spec') without requiring me to click into every discussion. When I see a discussion that seems important or risky, I follow it to receive notifications for future activity even though I'm not directly participating. Within the first 2 weeks, I was following 8 critical discussion threads and receiving updates as they progressed toward resolution without cluttering my attention with less relevant conversations. The discussion resolution status visibility transformed my blocker tracking - instead of manually asking 'did we decide X?' in meetings, I check the project dashboard showing 'Open Discussions (7), Resolved (23), Stale (3)'. The 3 stale discussions (threads with 5+ replies but no activity in 7 days) immediately signal potential blockers. I click into each stale discussion, assess why it stalled (waiting for specific person's input, needs executive decision, requires additional research), and take appropriate action. Last month I identified a stale discussion about deployment strategy that was blocking engineering team from starting infrastructure work - the discussion was waiting for DevOps input but the DevOps lead hadn't seen the @mention. I escalated directly to DevOps lead, they provided input within 2 hours, discussion was resolved, and engineering unblocked. Without stale discussion detection, this blocker would have remained invisible until engineers complained in stand-up days later. The permanent discussion documentation has made my onboarding process incredibly efficient - when new developer joined mid-project, instead of 3-hour explanation meeting, I shared project workspace link and told them to browse resolved discussions to understand past decisions. They spent 2 hours reading through discussion threads, came back with 3 specific questions about current work (not historical context), and were productive contributor by day 3. When stakeholders question project decisions, I share discussion thread links showing complete decision context including alternatives considered, trade-offs evaluated, and resolution rationale. This documentation protects both the decision quality and the team's credibility with leadership."
    emotional_resolution: "I now feel confident that I have comprehensive project visibility without being overwhelmed by every conversation detail. The team activity feed gives me ambient awareness of project discussions with just-right information density - I can scan activity in 10 minutes and identify important threads without reading every comment. I trust the notification system to alert me when discussions I'm following have important updates rather than constantly checking across multiple tools and channels. The discussion resolution tracking eliminates my anxiety about hidden blockers - I can see at a glance which discussions are unresolved or stale and proactively address them before they cause project delays. When stakeholders ask about project decisions, I feel prepared sharing discussion thread links with complete context rather than fumbling for partial recollections or defending decisions without evidence. The permanent discussion documentation has reduced my onboarding overhead from 3 hours of verbal explanation per new team member to 30 minutes answering specific questions after they've done self-service learning through discussion history. I've reclaimed 5-7 hours per week previously spent hunting for context across Slack, Linear, Figma, and Google Docs, reinvesting that time into strategic project planning and stakeholder communication. Most importantly, I feel like I'm enabling team collaboration and decision quality rather than just reacting to coordination problems - the tools help surface issues early (stale discussions) and preserve institutional knowledge (decision rationale) making my project coordination work more proactive and impactful. This shift from reactive firefighting to proactive facilitation has made my role significantly more satisfying and effective."
  - id: executive-reviewer
    name: Executive Reviewer
    role: Senior Leadership
    description: Executive stakeholder reviewing strategic documents and major decisions on monthly basis. Needs to quickly understand key discussions and decisions without reading every comment thread. Reviews 5-10 major documents per month with 30-60 minutes available per document. Values decision summaries and resolution clarity over detailed discussion chronology.
    goals:
    - Quickly understand key decisions made and rationale without reading full discussion threads
    - Identify unresolved questions or concerns that require executive input or decision
    - Assess quality of team collaboration and decision-making processes through discussion patterns
    - Provide targeted feedback on strategic aspects without getting pulled into tactical details
    pain_points:
    - Insufficient time to read detailed discussion threads but need to understand decision outcomes
    - Difficult to identify which discussions need executive attention vs those adequately resolved at team level
    - Cannot assess collaboration quality without visibility into discussion patterns (resolution time, participant engagement)
    - Providing feedback often creates new discussion branches making it hard to track if feedback was addressed
    usage_context: Monthly strategic document review and quarterly portfolio assessment. Occasional targeted input on specific decisions requiring executive perspective. Infrequent direct comment participation but regular resolution summary reading.
    technical_proficiency: basic
    current_situation: "As a VP of Engineering reviewing strategic technical decisions across 4 teams (50 engineers, 30-40 major decisions per quarter), I'm responsible for ensuring decision quality and alignment with company strategy but I lack time and tools for effective review. When team leads share technical proposals or ADRs for my review, they send PDF exports or Google Doc links via email with request 'please review and approve by Friday'. I have 45-60 minutes to review each document but documents often have 15-25 Slack discussions, Linear comment threads, and Google Doc suggestions attached. I cannot possibly read through all discussion history to understand context. I resort to skimming document content and asking team lead in meeting 'what's the key decision here and why did you choose this approach?' Often the lead's verbal summary emphasizes different aspects than what discussion threads covered, and I wonder if I'm missing important concerns raised by team members. Last quarter I approved an architecture decision that seemed sound based on lead's summary, but discovered 2 months later that 3 senior engineers had raised significant concerns in discussion threads I never saw. Those concerns proved valid - we ended up partially reversing the decision after hitting the predicted issues, wasting 8 weeks of implementation time. I have no visibility into unresolved discussions that might need my input - sometimes teams are stuck waiting for executive decision but I don't know they're waiting because the question is buried in a Slack thread I'm not monitoring. When I provide feedback on strategic docs, I send comments via email or Slack which team leads manually incorporate. I have no way to verify if my feedback was actually addressed or track if discussion spawned by my feedback reached resolution. During quarterly reviews, I try to assess team collaboration quality but lack objective metrics - I can see delivery outcomes (projects completed, timeline adherence) but not the discussion and decision-making process quality that leads to those outcomes. Are teams documenting decision rationale? Are decisions being made efficiently or stalling unnecessarily? Are diverse perspectives being included in discussions? I have no data to answer these questions."
    transformation_moment: "When I started reviewing strategic documents using inline collaboration with discussion resolution summaries, the improvement in review efficiency and confidence was immediate. The first document I reviewed post-implementation was an ADR on microservices migration strategy with 18 discussion threads attached. Instead of reading 18 full discussion threads (would take 90+ minutes), I scanned the discussion resolution summaries in 8 minutes - each summary showed decision outcome in 2-3 sentences (e.g., 'Question: Should we migrate all services or start with subset? Resolution: Start with 3 pilot services - customer-api, order-api, inventory-api. See thread for selection criteria.'). This gave me rapid understanding of key decisions made. I identified 2 strategic decisions requiring deeper review (service boundary definition, data consistency approach), drilled into those specific threads reading full 8-comment discussions, and felt confident I understood the critical technical choices and trade-offs considered. Total review time: 25 minutes vs previous 60+ minutes, with higher confidence in my understanding. The unresolved discussion visibility transformed my proactive input capability - I discovered 2 discussions flagged 'Needs Executive Decision' where teams were genuinely stuck waiting for strategic direction. One was about budget allocation for migration phases ($200k decision), the other about timeline prioritization affecting product roadmap. Both had been waiting 4 days for my input but I hadn't known because discussions were buried in document I hadn't reviewed yet. I provided decisions within 24 hours, unblocking both teams. The unresolved flagging means I now see executive-level blockers within 1-2 days instead of discovering them weeks later when timeline slips become visible. When I provided strategic feedback via inline comment ('Consider phased rollback strategy for each service migration'), I received notification when discussion spawned from my comment reached resolution. The resolution summary said 'Added phased rollback section to migration plan per executive feedback. Each service will have 72-hour rollback window with automated health checks.' This confirmed my feedback was incorporated and gave me confidence the concern was addressed properly. The collaboration analytics dashboard became my quarterly review centerpiece - I presented to board showing: (1) Decision documentation rate improved from 40% to 82% of major decisions having resolution summaries, (2) Average discussion resolution time decreased from 5.8 days to 2.4 days showing improved decision velocity, (3) Discussion participation metrics showing 65% of decisions had input from 3+ engineers indicating healthy diverse perspectives. One board member commented 'This is the most objective view of engineering decision quality I've seen at any portfolio company - gives me real confidence in the team's execution capability.'"
    emotional_resolution: "I now feel confident providing strategic oversight on technical decisions with appropriate information density rather than either missing critical context or drowning in tactical details. The discussion resolution summaries give me exactly what I need - concise decision outcomes with rationale in 2-3 sentences, with option to drill into full thread if needed. I can review a document with 20 discussions in 30 minutes by reading resolution summaries, identify the 2-3 most strategic decisions, and drill into those specific threads for full context. The unresolved discussion visibility with executive escalation tagging ensures I'm aware when teams need executive input - instead of teams being stuck waiting without my knowledge, I see flagged discussions requiring executive decision and can provide input proactively. When I provide strategic feedback via inline comments, I can track discussion resulting from my feedback and see when it reaches resolution or if follow-up is needed, giving me confidence my input is being appropriately incorporated. The collaboration analytics have given me objective visibility into team decision-making health - I can see average discussion resolution times by team (Team A: 2.3 days, Team B: 6.8 days suggesting process or clarity issues), decision documentation completeness (percentage of major decisions with resolution summaries), and discussion participation patterns (are decisions being made by single person or with diverse input). This data helps me identify teams needing process support or cultural development rather than relying on subjective impressions. During quarterly reviews with board, I confidently report on organizational decision quality using concrete metrics (decision documentation rate, resolution efficiency trends, institutional knowledge accumulation) rather than anecdotal examples. This evidence-based leadership approach has increased board confidence in our engineering organization and my effectiveness as executive leader. Most importantly, I feel like I'm enabling high-quality distributed decision-making rather than being bottleneck - teams make good decisions with appropriate documentation and escalate to me only when genuinely needed, creating scalable organizational capability."
dependencies:
  requires:
  - id: fd-007
    name: Organization & Workspace Management
    reason: 'Collaboration features require organization/team/project hierarchy for permission scoping, notification routing, and activity feed boundaries. Comments and discussions inherit permissions from parent artifact, @mentions validate against team membership, activity feeds aggregate by team/project structure. Cannot implement contextual collaboration without underlying workspace organization.

      '
  - id: fd-001
    name: Knowledge Discovery Engine
    reason: 'Discussion search and discovery require semantic search capability to find relevant past discussions by topic, keywords, or resolution summary. Users need to search discussion threads independently from document content. AI-assisted discussion summarization and related discussion suggestions require semantic understanding of discussion topics. Requires search infrastructure from fd-001.

      '
  enables:
  - id: fd-010
    name: Knowledge Base Content Management
    reason: 'Structured content management benefits from collaboration context showing which content sections are actively discussed, questioned, or need improvement. Discussion patterns inform content quality metrics and editorial workflows. Once inline collaboration establishes discussion patterns, content management can leverage that data for quality improvement.

      '
boundaries:
  non_goals:
  - Real-time collaborative editing (multiplayer cursors, live typing indicators) - Scope limited to async threaded discussions, not synchronous co-editing. Real-time collaborative editing requires WebSocket infrastructure, conflict resolution algorithms, and operational transformation adding 60+ engineering days. Use cases primarily require async review/feedback rather than simultaneous editing. Tools like Google Docs or Figma provide real-time editing for specific artifact types where needed. May consider in v2.0 if data shows strong demand.
  - Video/audio commenting or screen recording annotations - Scope limited to text-based discussions with file attachments, not embedded media recording. Video/audio commenting requires media processing pipeline, transcription services, and significant storage overhead adding 40+ engineering days for use case affecting <5% of discussions based on other platforms. Users can attach recorded videos as files if needed for high-value use cases. Rich text, images, and file attachments sufficient for MVP.
  - External guest collaboration (sharing artifacts with users outside organization) - Collaboration features limited to authenticated organization members with proper permissions. Guest access requires guest user management, time-limited access controls, and watermarking/download restrictions adding 30+ engineering days for security and compliance concerns. Organizations needing external collaboration can export artifacts to shared documents or use screen sharing. May consider secure guest access in v2.0 for customer feedback workflows.
  - Automated discussion moderation or sentiment analysis - System captures discussion content without automated moderation, sentiment scoring, or toxicity detection. Automated moderation requires ML models, training data, and careful policy development adding 50+ engineering days with high risk of false positives. Organization size (typically <500 users) enables human moderation by team leads if needed. Sentiment analysis interesting for analytics but not validated as priority for MVP. May revisit if toxicity or collaboration quality issues emerge.
  constraints:
  - Technical - Discussion threads limited to 5 levels of nesting to maintain readable UI and prevent infinite recursion. Deeply nested discussions (>5 levels) must be moved to new root-level thread. Affects <2% of discussions based on similar platforms but necessary for UX and technical implementation simplicity.
  - Business - MVP timeline is 3 months limiting implementation to core commenting, threading, and notifications. Advanced features (AI-generated discussion summaries, automated topic extraction, discussion sentiment trends) deferred to v2.0. May require manual processes for discussion organization until v2.0 automation available.
  - Technical - Discussion search indexes updated with 5-minute lag (not real-time) due to search infrastructure constraints. Newly created discussions may not appear in search results for up to 5 minutes. Affects edge cases where user creates discussion then immediately searches for it, but 5-minute lag acceptable for normal workflows where search queries are for historical discussions.
  - Third-party - Slack/Teams notification integration limited to outbound notifications (comments/mentions sent to external tools) without inbound support (cannot create platform discussions from Slack messages). Bidirectional integration requires webhooks, message mapping, and identity linking adding 25+ engineering days with ongoing maintenance complexity. Outbound notifications sufficient for MVP - users can see activity in Slack but must return to platform to participate in discussions, maintaining platform as source of truth.
